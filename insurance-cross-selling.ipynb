{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73291,"databundleVersionId":8930475,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-30T07:32:52.358711Z","iopub.execute_input":"2024-07-30T07:32:52.359866Z","iopub.status.idle":"2024-07-30T07:32:53.582915Z","shell.execute_reply.started":"2024-07-30T07:32:52.359822Z","shell.execute_reply":"2024-07-30T07:32:53.581621Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e7/sample_submission.csv\n/kaggle/input/playground-series-s4e7/train.csv\n/kaggle/input/playground-series-s4e7/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/playground-series-s4e7/train.csv\")\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T07:32:53.585780Z","iopub.execute_input":"2024-07-30T07:32:53.586469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"train_num = train[['Age','Annual_Premium','Vintage']]\ntrain_cat = train[['Gender','Driving_License','Region_Code','Previously_Insured','Vehicle_Age','Vehicle_Damage','Policy_Sales_Channel']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyse %response by gender. Males appear to respond more positively.\ngender_pivot = pd.pivot_table(train, index='Response', columns='Gender', values='id', aggfunc='count')\ngender_pivot['Female%'] = gender_pivot['Female']/gender_pivot['Female'].sum()*100\ngender_pivot['Male%'] = gender_pivot['Male']/gender_pivot['Male'].sum()*100\ngender_pivot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot histogram by age\nplt.hist(train['Age'], bins=200);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalising histogram by age\nplt.hist(np.log(train['Age']), bins=200);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyse and visualise %response by age. Response appears to peak around 30s, when people are more likely to own/drive a car.\nage_pivot = pd.pivot_table(train, index='Response', columns='Age', values='id', aggfunc='count').T\nage_pivot['Response%'] = age_pivot[1]/(age_pivot[0]+age_pivot[1])*100\nage_pivot\nsns.barplot(x=age_pivot.index, y=age_pivot['Response%']).set_ylabel('Positive Response %')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyse %response of those with(out) driving license. Those with license are more likely to require insurance.\npd.pivot_table(train, index='Response', columns='Driving_License', values='id', aggfunc='count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting distribution by region code\nregion_bar = sns.barplot(x=train['Region_Code'].value_counts().index, y=train['Region_Code'].value_counts()/11504798*100)\nregion_bar.set_title('Region Code')\nregion_bar.set_ylabel('% of total')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing positive response % by region\nregion_pivot = pd.pivot_table(train, index='Response', columns='Region_Code', values='id', aggfunc='count').T\nregion_pivot['Response%'] = region_pivot[1]/(region_pivot[0]+region_pivot[1])*100\nsns.barplot(x=region_pivot.index, y=region_pivot['Response%']).set_ylabel('Positive Response %')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyse %response of those (not) previously insured. Those who never bought insurance before are more likely to require insurance.\npd.pivot_table(train, index='Response', columns='Previously_Insured', values='id', aggfunc='count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyse %response by vehicle age. Respondents with older vehicles more likely to require insurance.\nvehicle_age_pivot = pd.pivot_table(train, index='Response', columns='Vehicle_Age', values='id', aggfunc='count')\nvehicle_age_pivot = vehicle_age_pivot[['< 1 Year','1-2 Year','> 2 Years']]\nvehicle_age_pivot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyse %response by vehicle damage. Those who have damaged vehicles are more likely to require insurance.\npd.pivot_table(train, index='Response', columns='Vehicle_Damage', values='id', aggfunc='count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Annual_Premium'].value_counts()/11504798*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyse distribution of annual premiums.\nplt.hist(train['Annual_Premium'], bins=500);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting outlier rows with Annual Premiums exceeding $150,000\ntrain.loc[train['Annual_Premium'] > 150000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying log transformation\nplt.hist(np.log(train['Annual_Premium']), bins=500);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Policy_Sales_Channel'].value_counts()/11504798*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting distribution by policy sales channel\nchannel_bar = sns.barplot(x=train['Policy_Sales_Channel'].value_counts().index, y=train['Policy_Sales_Channel'].value_counts()/11504798*100)\nchannel_bar.set_title('Policy_Sales_Channel')\nchannel_bar.set_ylabel('% of total')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing positive response % by sales channel\nchannel_pivot = pd.pivot_table(train, index='Response', columns='Policy_Sales_Channel', values='id', aggfunc='count').T\nchannel_pivot['Response%'] = channel_pivot[1]/(channel_pivot[0]+channel_pivot[1])*100\nsns.barplot(x=channel_pivot.index, y=channel_pivot['Response%']).set_ylabel('Positive Response %')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channels = train['Policy_Sales_Channel'].value_counts()\nchannels\nmain_channels = channels.head(16)\nmain_channels\nmain_channels.index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting histogram distribution by customer vintage\nplt.hist(train['Vintage'], bins=500);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysing for any correlation between Vintage and positive response rate\nvintage_pivot = pd.pivot_table(train, index='Response', columns='Vintage', values='id', aggfunc='count').T\nvintage_pivot['Response%'] = vintage_pivot[1]/(vintage_pivot[0]+vintage_pivot[1])*100\nsns.scatterplot(x=vintage_pivot.index, y=vintage_pivot['Response%']).set_ylabel('Postive Response %')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Insights gained and observations made\n**1. Gender**\n* Males have a slightly higher rate of positive response (Males: 13.97% vs Females: 10.33%). \n\n**2. Age**\n* Age distribution displays right-skewing of the data.\n* Positive response rate is highest between age 30 and 72 (middle-aged customers). This suggests that this age group should be the target focus of the insurance company.\n\n**3. Driving License**\n* Most of the data is obtained from those possessing a driving license.\n* Additionally, the positive response rate is much higher with customers possessing a driving license, which is to be expected.\n\n**4. Region Code**\n* Distribution of region codes indicate that most of the data has been obtained from a single region (Region 28 represents 30% of the data)\n\n**5. Previously Insured**\n* Those who never bought insurance before are significantly more likely to require insurance.\n\n**6. Vehicle Age**\n* Most of the data is obtained from those possessing vehicles aged 2-years or less.\n* Can be observed that the older the vehicle possessed by the customer, the more likely the customer requires insurance.\n\n**7. Vehicle Damage**\n* Can be observed that customers with damaged vehicles are more likely to require insurance.\n\n**8. Annual Premium**\n* Annual Premium distribution displays right-skewing of the data, with 18.36% of customers paying 2,630 a year.\n* Suggests that most customers pay low premiums, while a tiny proportion of outlier customers pay >100,000 worth of annual premiums.\n\n**9. Policy Sales Channel**\n* Distribution shows that most of the data has been obtained from a handful of sales channels (Channel 152, 26 and 124 make up 77% of the data).\n\n**10. Vintage**\n* Distribution by vintage appears relatively even, which shows that the customers have been with the insurance company for various lengths of time.\n* Appears to show almost no correlation with Response.","metadata":{}},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\n\ntrain_copy = train.copy()\n\n# Using ColumnTransformer to apply ordinal encoding and feature scaling to the respective categorical and numeric columns\npreprocessor = ColumnTransformer(transformers=[\n    ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), ['Gender','Region_Code','Vehicle_Age','Vehicle_Damage','Policy_Sales_Channel']),\n    ('num', StandardScaler(), ['Age','Annual_Premium'])\n], remainder = 'passthrough')\n\n# Setting up pipeline\npipeline = Pipeline(steps=[\n    ('pre', preprocessor)\n])\n\ny = train_copy['Response']\nX = train_copy.drop(columns=['Response', 'id'])\nX_preprocessed = pipeline.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV, KFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nX_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n\n# Using Decision Tree and XGBoost classifier models. Random Forest took too long to train as it does not scale well with large datasets like this.\nmodels = {\n    'DecisionTree': DecisionTreeClassifier(random_state=42),\n    'XGBoost': XGBClassifier(random_state=42)\n}\n\n# Using GridSearchCV to perform hyperparameter tuning and reduce over-fitting.\nparam_grids = {\n    'DecisionTree': {\n        'max_depth': [10, 15, 20],\n        'min_samples_split': [2, 5, 10]\n    },\n    'XGBoost': {\n        'max_depth': [10, 15, 20],\n        'min_child_weight': [10, 15, 20],\n        'gamma': [2, 4, 6]\n    }\n}\n\n# 2-fold cross-validation\ncv = KFold(n_splits=2, shuffle=True, random_state=42)\n\n# Training prediction and evaluation using ROC AUC\ngrids = {}\nfor model_name, model in models.items():\n    grids[model_name] = GridSearchCV(estimator=model,\n                                    param_grid=param_grids[model_name],\n                                    cv=cv,\n                                    scoring='roc_auc',\n                                    n_jobs=-1,\n                                    verbose=2)\n    grids[model_name].fit(X_train, y_train)\n    best_params = grids[model_name].best_params_\n    best_score = grids[model_name].best_score_\n\n    print(f'Best parameters for {model_name}: {best_params}')\n    print(f'Best accuracy for {model_name}: {best_score}\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/playground-series-s4e7/test.csv\")\ntest_id = test['id']\ntest = test.drop(columns=['id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforming test data\ntest_preprocessed = pipeline.transform(test)\nprint(X_preprocessed.shape)\nprint(test_preprocessed.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction and submission using better-performing model\nmodel = XGBClassifier(max_depth=10, min_child_weight=20, gamma=2).fit(X_train, y_train)\ny_pred = model.predict_proba(test_preprocessed)[:,1]\noutput = pd.DataFrame({'id': test_id, 'Response': y_pred})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}